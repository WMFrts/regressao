# -*- coding: utf-8 -*-
"""regressao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r29FOTMqKjFxTHqeFwj3kKdhiEElpZTK

<h2><center>REGRESSÃO</center></h2>
<p align="Justify">É uma técnica que permite quantificar e inferir a relação de uma variável dependente (variável de resposta, objetivo) com variáveis independentes (variáveis explicativas, previsoras). A análise da regressão pode ser usada como um método descritivo da análise de dados (por exemplo, o ajustamento de curvas).</p>
<hr size="1" width="100%" align="center" noshade>

<h3><center>1 REGRESSÃO LINEAR SIMPLES</center></h3>
<p align="Justify">Inclui somente duas variáveis: uma independente e outra dependente. 
A variável dependente é aquela que está sendo explicada, 
enquanto a variável independente é aquela que é utilizada 
para explicar a variação na variável dependente.</p>
"""

#biblioteca plotly para visualização de gráficos dinâmicos:

!pip install plotly --upgrade

#plotly,seaborn e matplotlib para gerar e visualizar gráficos;
#pandas parar carregar o arquivo .csv;
#numpy para realizar os cálculos em Arrays Multidimensionais.

import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns 
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

"""**1.1 BASE PLANO DE SAÚDE - EXPLORAÇÃO DE DADOS** 
<p align="Justify">Base de dados ilustrativa para estudo de regressão linear simples com 10 registros. Mostra na primeira coluna a idade; já na segunda, o custo.</p>
"""

#Carregamento do arquivo

base_plano_saude = pd.read_csv('plano_saude.csv')
base_plano_saude

"""**1.2 PERGUNTA SOBRE O CONTEXTO**
<p align="Justify">De acordo com os dados apresentados, quanto poderia custar o plano 
saúde dependendo da idade da pessoa?


Essa pergunta pode ser respondida por meio de um modelo de regressão
linear simples, pois há apenas duas variáveis: a dependente (custo) e a 
independente, previsora (idade)

"""

#criação da variável x que armazenará o atributo previsor (idade)
#iloc[:,0] seleciona o conj. de registros de todas as linhas da coluna 0
#.values converte para o formato np array

x_plano_saude = base_plano_saude.iloc[:, 0].values 
x_plano_saude

#mesmo procedimento para a variável y dependente (custo)
y_plano_saude = base_plano_saude.iloc[:, 1].values 
y_plano_saude

"""**1.3 COEFICIENTE DE CORRELAÇÃO**
<p align="Justify">O coeficiente de correlação de Pearson é um teste que mede a relação estatística entre duas variáveis contínuas. 

Apresenta um intervalo de valores de +1 a -1. Um valor de 0 indica que não há associação entre as duas variáveis. Um valor maior que 0 indica uma associação positiva. Isto é, à medida que o valor de uma variável aumenta, o mesmo acontece com o valor da outra variável.
"""

# A correlação entre as duas variáveis é 0.93091958
# 93% do custo talvez seja explicado pela idade 

np.corrcoef(x_plano_saude, y_plano_saude)

# Esta em forma de vetor, precisa mudar para matriz

x_plano_saude.shape

# .reshape() para mudar para forma de matriz
# Então, poderá ser enviada para o algoritmo de regressão

x_plano_saude = x_plano_saude.reshape(-1,1)
x_plano_saude

# importação para o algoritmo
# função fit() para executar o treinamento

from sklearn.linear_model import LinearRegression
regressor_plano_saude = LinearRegression()
regressor_plano_saude.fit(x_plano_saude, y_plano_saude)

# y = b0 + b1.x, equação que representa o modelo
# treinamento = encontrar b0 e b1 para cada atributo

# b0 = intercept (intersecção com o eixo y)
regressor_plano_saude.intercept_

# b = coeficiente (inclinação da reta)
regressor_plano_saude.coef_

# método predict para descobrir a associação 
# x_plano_saude está relacionado as idades

previsoes = regressor_plano_saude.predict(x_plano_saude)
previsoes

# gráfico de dispersão para visualizar o resultado
# grafico = px.scatter(x = x_plano_saude, y= y_plano_saude)
# grafico.show()

# antes, x_plano_saude está em formato de matriz 

x_plano_saude

# para fazer o gráfico, precisa retornar para o formato de vetor
# para isso, utiliza a função .ravel do np

x_plano_saude.ravel()

# Novamente,  o código para mostrar o gráfico
# Aqui, mostra apenas os pontos idade e custo

grafico = px.scatter(x = x_plano_saude.ravel(), y= y_plano_saude)
grafico.show()

# Agora, com as previsões do algoritmo
# acrescentam-se as previsões com a função .add_scatter

grafico = px.scatter(x = x_plano_saude.ravel(), y= y_plano_saude)
grafico.add_scatter(x = x_plano_saude.ravel(), y= previsoes, name = 'Regressão')
grafico.show()

# para saber a qualidade do algoritmo
regressor_plano_saude.score(x_plano_saude, y_plano_saude)

# para saber a distância dos valores reais em relação à regressão linear
# Train R² = 0.867 indica a qualidade do algoritmo

from yellowbrick.regressor import ResidualsPlot
visualizador = ResidualsPlot(regressor_plano_saude)
visualizador.fit(x_plano_saude, y_plano_saude)
visualizador.poof()

"""**1.4 BASE PREÇO DAS CASAS - EXPLORAÇÃO DE DADOS**

"""

base_casas = pd.read_csv('house_prices.csv')
base_casas

base_casas.describe()

# há valores faltantes? Quantos seriam?
base_casas.isnull().sum()

# indicação das correlações 

base_casas.corr()

# com sns é possível visualizar "melhor" a correlação

sns.heatmap(base_casas.corr());

# Agora com os valores:
# "Ninguém quer fazer um gráfico ruim. Mas acontece" - Storytelling Com Dados

sns.heatmap(base_casas.corr(), annot= True);

# aumentar o tamanho da figura:
# criação da variável e utilização do plt
# passagem do tamanho para figure

figura = plt.figure(figsize = (18, 18))
sns.heatmap(base_casas.corr(), annot= True);

"""**1.5 PERGUNTA SOBRE O CONTEXTO**
<p align="Justify">De acordo com os dados apresentados, baseado na metragem, qual seria o preço da casa?


A regressão linear simples também pode dar a resposta. Nesse caso, a variável x é o previsor, e a variável y está relacionada com o preço da casa
"""

# metragem da casa

x_casas = base_casas.iloc[:, 5:6].values
x_casas

y_casas = base_casas.iloc[:,2].values
y_casas

# divisão da base de dados entre treinamento e teste
# "teste_size = 0.3" indica que 30% da base será para teste,
# logo, 70% da base será para treinar

import sklearn as sk

from sklearn.model_selection import train_test_split
x_casas_treinamento, x_casas_teste, y_casas_treinamento, y_casas_teste = train_test_split(x_casas, y_casas, test_size = 0.3, random_state = 0)

# o treinamento irá acontecer com 15129 registros

x_casas_treinamento.shape, y_casas_treinamento.shape

# o teste do algoritmo será feito com 6484 registros

x_casas_teste.shape, y_casas_teste.shape

"""**1.6 CRIAÇÃO DO MODELO DE REGRESSÃO LINEAR**"""

from sklearn.linear_model import LinearRegression
regressor_simples_casa = LinearRegression()
regressor_simples_casa.fit(x_casas_treinamento, y_casas_treinamento)

# b0

regressor_simples_casa.intercept_

# b1

regressor_simples_casa.coef_

# avaliação de desempenho na própria base de treinamento
# um bom desempenho, deve ser próximo de 1

regressor_simples_casa.score(x_casas_treinamento, y_casas_treinamento)

# mais um baixo desempenho do algoritmo

regressor_simples_casa.score(x_casas_teste, y_casas_teste)

# geração de previsões para o treinamento

previsoes = regressor_simples_casa.predict(x_casas_treinamento)
previsoes

# x_casas_treinamento.ravel() para transformar o vetor em matriz
# o gráfico retorna a previsão para cada registro da base de dados de treinamento

grafico = px.scatter(x = x_casas_treinamento.ravel(), y = previsoes)
grafico

# Novo gráfico com todos os dados:
# no eixo y serão passados os dados reais: y = y_casas_treinamento
# Voltar na importação de bibliotecas para "import plotly.graph_objects as go"

grafico1 = px.scatter(x = x_casas_treinamento.ravel(), y = y_casas_treinamento)

grafico3 = go.Figure(data = grafico1.data)   #gera dois gráficos e faz a combinação 
grafico3

# concatenação com as previsões

grafico1 = px.scatter(x = x_casas_treinamento.ravel(), y = y_casas_treinamento)
grafico2 = px.line(x = x_casas_treinamento.ravel(), y = previsoes )   #gráfico de linha
grafico3 = go.Figure(data = grafico1.data + grafico2.data)   #concatenação
grafico3

grafico1 = px.scatter(x = x_casas_treinamento.ravel(), y = y_casas_treinamento)   #em azul
grafico2 = px.line(x = x_casas_treinamento.ravel(), y = previsoes )   #gráfico de linha
grafico2.data[0].line.color = 'black'   #previsões em preto
grafico3 = go.Figure(data = grafico1.data + grafico2.data)   #concatenação
grafico3

"""**1.7 MÉTRICAS DE AVALIAÇÃO**

<ul>
<li>Mean Squared Error (MSE): calcula a média dos erros do modelo ao quadrado - diferenças menores recebem menos peso que as maiores. </li>

<li>Root Mean Squared Error (RMSE): é a raiz quadrada do MSE. O erro volta a ter as unidades de medida originais da variável dependente.</li>

<li>Mean Absolute Error (MAE): diferença absoluta entre as previsões eos valores reais - atribui o mesmo peso a todas as diferenças, de maneira linear.</li>

<li>Mean Absolute Percentage Error (MAPE): calcula a média percentual do desvio absoluto entre as previsões e a realidade. </li>
</ul>
"""

# previsões para cada uma das casas do banco de dados

previsoes_teste = regressor_simples_casa.predict(x_casas_teste)
previsoes_teste

# é necessário fazer o comparativo com a variável que apresenta os valores reais
# para a primeira casa, o valor é 297000 e o algoritmo previu 360116...

y_casas_teste

# valor absoluto da diferença entre o preço real e a previsão

abs(y_casas_teste - previsoes_teste)

# Mean Absolute Error (MAE):
# Em média erra 172604 para mais ou para menos no preço das casas

abs(y_casas_teste - previsoes_teste).mean()

# Mean Absolute Error (MAE) e
# Mean Squared Error (MSE) com sklearn

from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_absolute_error(y_casas_teste, previsoes_teste), mean_squared_error(y_casas_teste, previsoes_teste)

# Mean Absolute Percentage Error (MAPE)

from sklearn.metrics import  mean_absolute_percentage_error
mean_absolute_percentage_error(y_casas_teste, previsoes_teste)

# Root Mean Squared Error (RMSE): 

np.sqrt(mean_squared_error(y_casas_teste, previsoes_teste))

# geração do gráfico considerando a base de dados do teste
# para visualizar se haverá algum tipo de diferença

grafico1 = px.scatter(x = x_casas_teste.ravel(), y = y_casas_teste)   #em azul
grafico2 = px.line(x = x_casas_teste.ravel(), y = previsoes_teste )   #gráfico de linha
grafico2.data[0].line.color = 'black'   #previsões em preto
grafico3 = go.Figure(data = grafico1.data + grafico2.data)   #concatenação
grafico3

"""<h3><center>2 REGRESSÃO LINEAR MÚLTIPLA</center></h3>

<p align="Justify">É um modelo de análise que usamos quando modelamos a relação linear entre uma variável de desfecho contínua e múltiplas variáveis preditoras que podem ser contínuas ou categóricas.
"""

base_casas

# criação de variável

x_casas = base_casas.iloc[:,3:19].values
x_casas

y_casas = base_casas.iloc[:, 2].values
y_casas

# divisão da base entre treinamento e teste:

from sklearn.model_selection import train_test_split
x_casas_treinamento, x_casas_teste, y_casas_treinamento, y_casas_teste = train_test_split(x_casas, y_casas, test_size = 0.3, random_state = 0)

# criação do regressor e treinamento

regressor_multiplo_casas = LinearRegression()
regressor_multiplo_casas.fit(x_casas_treinamento, y_casas_treinamento)

# b0:

regressor_multiplo_casas.intercept_

regressor_multiplo_casas.coef_

# b1, b2, ...b16:
# Nesse caso, y = b0 + b1.x1 + b2.x2...+b16.x16

len(regressor_multiplo_casas.coef_)

# para a regressão linear simples foi de 0.40

regressor_multiplo_casas.score(x_casas_treinamento, y_casas_treinamento)

# agora na base de dados de teste

regressor_multiplo_casas.score(x_casas_teste, y_casas_teste)

previsoes = regressor_multiplo_casas.predict(x_casas_teste)
previsoes

# precisa ser comparado com y_casas_teste

y_casas_teste

# Mean Absolute Error (MAE) com sklearn

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_casas_teste, previsoes)

"""<h3><center>3 REGRESSÃO POLINOMIAL</center></h3>

<p align="Justify">A regressão polinomial é um caso particular de regressão linear múltipla. É utilizadA quando a função que relaciona a variável resposta y com as explicativas x1, x2, ..., xn é uma curva, então representada por um polinômio.

**3.1 BANCO PLANO DE SAÚDE 2 - EXPLORAÇÃO DE DADOS**
<p align="Justify">De acordo com os dados apresentados, quanto poderia custar o plano saúde dependendo da idade da pessoa?
"""

# carregamento do arquivo

base_plano_saude2 = pd.read_csv('plano_saude2.csv')
base_plano_saude2

# criação variável x com o atributo previsor (idade)
# criação variável y com a resposta esperada (custo)
# .iloc[:,0:1] todos os registros coluna 0 até a 1 (busca a coluna 0)
# .values transforma no formato np array

x_plano_saude2 = base_plano_saude2.iloc[:,0:1].values
y_plano_saude2 = base_plano_saude2.iloc[:,1].values

# verificação

x_plano_saude2, y_plano_saude2

# percebe-se que a distribuição dessa base é uma curva

graf = px.scatter(x = x_plano_saude2.ravel(), y = y_plano_saude2)
graf

"""**3.2 CRIAÇÃO DO MODELO DE REGRESSÃO POLINOMIAL**"""

# transformações por conta da classe PolynomialFeatures
# criação de variável com o objeto de mesma classe
# degree indica a potência que será escolhida

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree = 2)
x_plano_saude2_poly = poly.fit_transform(x_plano_saude2)

# 10 registros e 3 colunas

x_plano_saude2_poly.shape

# **Explicação sobre a matriz**
# linha: [1.000e+00, 1.800e+01, 3.240e+02]
# 1.000e+00 padrão da classe PolynomialFeatures para o primeiro elemento
# 1.800e+01 idade 18, era esse valor na base
# 3.240e+02 idade 18²

x_plano_saude2_poly

# com degree = 4
# esses dados serão enviados para o algoritmo

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree = 4)
x_plano_saude2_poly = poly.fit_transform(x_plano_saude2)

# aplica o mesmo algoritmo da regressão linear

regressor_saude_polinomial = LinearRegression()
regressor_saude_polinomial.fit(x_plano_saude2_poly, y_plano_saude2)   # treinamento

# b0

regressor_saude_polinomial.intercept_

# bn

regressor_saude_polinomial.coef_

"""**3.3 TESTE DO ALGORITMO**
<p align = Qual seria o custo do plano de saúde de acordo com a idade?

<p align="Justify">De acordo com o algoritmo de regressão polinomial, o custo do plano de saúde em relação à idade seria:
"""

# caso: pessoa de 40 anos 

novo = [[40]]   # matriz para novo registro ao algoritmo

novo = poly.transform(novo)   # mesmo processo feito para o banco de dados
novo

# o custo do plano de saúde para uma pessoa de 40 anos seria: R$1335,33

regressor_saude_polinomial.predict(novo)

"""**3.4 PREVISÕES**"""

# previsões de custo para as idades existentes no banco de dados

previsoes = regressor_saude_polinomial.predict(x_plano_saude2_poly)
previsoes

grafico = px.scatter(x = x_plano_saude2 [:,0], y= y_plano_saude2)
grafico.add_scatter(x = x_plano_saude2[:,0], y= previsoes, name = 'Regressão')
grafico.show()

# teste

'''
grafico1 = px.scatter(x = x_casas_teste.ravel(), y = y_casas_teste)   #em azul
grafico2 = px.line(x = x_casas_teste.ravel(), y = previsoes_teste )   #gráfico de linha
grafico2.data[0].line.color = 'black'   #previsões em preto
grafico3 = go.Figure(data = grafico1.data + grafico2.data)   #concatenação
grafico3
'''

graficoA = px.scatter(x = x_plano_saude2 [:,0], y= y_plano_saude2)   #em azul
graficoB = px.line(x = x_plano_saude2 [:,0], y = previsoes)   #gráfico de linha
graficoB.data[0].line.color = 'black'   #previsões em preto
graficoC = go.Figure(data = graficoA.data + graficoB.data)   #concatenação
graficoC.show()


'''
grafico = px.scatter(x = x_plano_saude2 [:,0], y= y_plano_saude2)
grafico.add_scatter(x = x_plano_saude2[:,0], y= previsoes, name = 'Regressão')
grafico.show()
'''

"""**3.5 BASE PREÇO DAS CASAS**

"""

# divisão da base em treinamento e teste
# essa divisão já foi feita para esses dados

x_casas_treinamento.shape, x_casas_teste.shape

"""**3.6 CRIAÇÃO DO MODELO DE REGRESSÃO POLINOMIAL**"""

from sklearn. preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree = 2)
x_casas_treinamento_poly = poly.fit_transform(x_casas_treinamento)   # fit_transform para ajuste inicial
x_casas_teste_poly = poly.transform(x_casas_teste)   # só precisa chamar a função transform

# eram 16 colunas: ((15129, 16), (6484, 16))
# agora são 153: ((15129, 153), (6484, 153))

x_casas_treinamento_poly.shape, x_casas_teste_poly.shape

# criação do regressor
# seguida do treinamento
# y_casas_treinamento é para prever, então não passou por transformação

regressor_casas_poly = LinearRegression()
regressor_casas_poly.fit(x_casas_treinamento_poly, y_casas_treinamento)

# score na base de treinamento

regressor_casas_poly.score(x_casas_treinamento_poly, y_casas_treinamento)

# score na base de teste

regressor_casas_poly.score(x_casas_teste_poly, y_casas_teste)

# previsões dos preços

previsoes = regressor_casas_poly.predict(x_casas_teste_poly)
previsoes

# respostas reais para comparar com as previsões
# o algoritmo previu 386279, quando o valor real é 297000
y_casas_teste

"""**3.7 MÉTRICAS DE AVALIAÇÃO**

"""

# Mean Absolute Error (MAE)

mean_absolute_error(y_casas_teste, previsoes)

# Mean Squared Error (MSE)

mean_squared_error(y_casas_teste, previsoes)

# Mean Absolute Percentage Error (MAPE)

mean_absolute_percentage_error(y_casas_teste, previsoes)

"""<h3><center>4 REGRESSÃO COM ÁRVORES DE DECISÃO</center></h3>

**4.1 BASE PLANO DE SAÚDE**
"""

x_plano_saude2

y_plano_saude2

# criação da árvore de decisão para regressão
# seguida de treinamento

from sklearn.tree import DecisionTreeRegressor
regressor_arvore_saude = DecisionTreeRegressor()
regressor_arvore_saude.fit(x_plano_saude2, y_plano_saude2)

previsoes = regressor_arvore_saude.predict(x_plano_saude2)
previsoes

# o score resultou em 1 devido aos splits

regressor_arvore_saude.score(x_plano_saude2, y_plano_saude2)

# Os dados foram divididos na árvore (splits) e resultaram nos valores exatos

grafico = px.scatter(x = x_plano_saude2.ravel(), y= y_plano_saude2)
grafico.add_scatter(x = x_plano_saude2.ravel(), y= previsoes, name = 'Regressão')
grafico.show()

# para visualizar os splits:

# A função arange cria um arranjo 
# contendo uma sequência de valores especificados em um intervalo com início e fim dados
# step: Este argumento indica o intervalo entre cada elemento do arranjo
# será utilizado step = 0.1 (pode ser tipo float e o padrão é 1)

x_teste_arvore = np.arange(min(x_plano_saude2), max(x_plano_saude2), 0.1)
x_teste_arvore

x_teste_arvore.shape

# conversão para matriz

x_teste_arvore = x_teste_arvore.reshape(-1, 1)

x_teste_arvore.shape

# divisões dos dados mais visíveis para perceber os splits

# ex: pessoas de 18 a 20 anos, neste split, serão relacionadas com o custo de R$470

grafico = px.scatter(x = x_plano_saude2.ravel(), y= y_plano_saude2)
grafico.add_scatter(x = x_teste_arvore.ravel(), y= regressor_arvore_saude.predict(x_teste_arvore), name = 'Regressão')
grafico.show()

"""**4.2 BASE PREÇO DAS CASAS**"""

# retomando os dados que já estão no banco

x_casas_treinamento.shape

y_casas_treinamento.shape

x_casas_teste.shape

"""**4.3 CRIAÇÃO DA REGRESSÃO COM ÁRVORES DE DECISÃO**"""

# criação da regressão
# treinamento com os atributos previsores(x) e objetivo(y)

regressor_arvore_casas = DecisionTreeRegressor() 
regressor_arvore_casas.fit(x_casas_treinamento, y_casas_treinamento)

# score na base de dados de treinamento

regressor_arvore_casas.score(x_casas_treinamento, y_casas_treinamento)

# score na base de dados de teste (que serve para a avaliação)

regressor_arvore_casas.score(x_casas_teste, y_casas_teste)

previsoes = regressor_arvore_casas.predict(x_casas_teste)
previsoes

y_casas_teste

# Mean Absolute Error (MAE)

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_casas_teste, previsoes)

"""<h3><center>5 REGRESSÃO COM RANDOM FOREST</center></h3>

**5.1 BASE PLANO DE SAÚDE 2**
"""

x_plano_saude2

y_plano_saude2

# criação da random forest para regressão
# seguida de treinamento

from sklearn.ensemble import RandomForestRegressor
regressor_random_forest_saude = RandomForestRegressor(n_estimators = 10)   # com 10 árvores
regressor_random_forest_saude.fit(x_plano_saude2, y_plano_saude2)

# score

regressor_random_forest_saude.score(x_plano_saude2, y_plano_saude2)

# reutilização e adaptação de código

# gráfico para deixar claro os splits que ocorrem, assim como em árvores de decisão

grafico = px.scatter(x = x_plano_saude2.ravel(), y= y_plano_saude2)
grafico.add_scatter(x = x_teste_arvore.ravel(), y= regressor_random_forest_saude.predict(x_teste_arvore), name = 'Regressão')
grafico.show()

"""**5.2 BASE PREÇO DAS CASAS**"""

x_casas_treinamento.shape

y_casas_treinamento

# criação da random forest
# seguida de treinamento

regressor_random_forest_casas = RandomForestRegressor (n_estimators= 100)
regressor_random_forest_casas.fit(x_casas_treinamento, y_casas_treinamento)

# score no banco de treinamento

regressor_random_forest_casas.score(x_casas_treinamento, y_casas_treinamento)

# score no banco de testes

regressor_random_forest_casas.score(x_casas_teste, y_casas_teste)

# geração das previsões dos preços para serem comparados com os reais

previsoes = regressor_random_forest_casas.predict(x_casas_teste)
previsoes

# EX: Valor real do 1º registro 297000 e o algoritmo previu 307788

y_casas_teste

# significa um erro de 67757 para mais ou para menos

from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_casas_teste, previsoes)

"""<h3><center>6 REGRESSÃO COM VETORES DE SUPORTE</center></h3>

**6.1 BASE PLANO DE SAÚDE**
"""

x_plano_saude2, y_plano_saude2

"""**6.2 SUPPORT VECTOR REGRESSION**
<ul>
<li>Mantém as mesmas características do Support Vector Machine (SVM) tem para a classificação </li>

<li>Apresenta o parâmetro epsilon, grau de tolerância que penaliza as imprecisões do treinamento.</li>
</ul>

**6.3 KERNELS**
<ul>
<li>Kernel Linear </li>

<li>Kernel Polinomial</li>

<li>Kernel rbf</li>

</ul>
"""

# criação, 
# com kernel linear
# seguido de treinamento 

from sklearn.svm import SVR
regressor_svr_saude_linear = SVR(kernel='linear')
regressor_svr_saude_linear.fit(x_plano_saude2, y_plano_saude2)

# os dados estão distribuídos em curva
# o algoritmo não consegue se adaptar bem com esses dados
# resultado parecido com a regressão linear simples

grafico = px.scatter(x = x_plano_saude2.ravel(), y= y_plano_saude2)
grafico.add_scatter(x = x_plano_saude2.ravel(), y= regressor_svr_saude_linear.predict(x_plano_saude2), name = 'Regressão')
grafico.show()

# Kernel polinomial

regressor_svr_saude_poly = SVR(kernel='poly', degree = 3)
regressor_svr_saude_poly.fit(x_plano_saude2, y_plano_saude2)

# o resultado do gráfico se assemelha à regressão polinomial
# há melhor adaptação aos dados

grafico = px.scatter(x = x_plano_saude2.ravel(), y= y_plano_saude2)
grafico.add_scatter(x = x_plano_saude2.ravel(), y= regressor_svr_saude_poly.predict(x_plano_saude2), name = 'Regressão')
grafico.show()

# kernel rbf
# treinamento

regressor_svr_saude_rbf = SVR(kernel='rbf')
regressor_svr_saude_rbf.fit(x_plano_saude2, y_plano_saude2)

# resulta em uma reta 
# porque os dados precisam estar normalizados para o algoritmo SVM

grafico = px.scatter(x = x_plano_saude2.ravel(), y= y_plano_saude2)
grafico.add_scatter(x = x_plano_saude2.ravel(), y= regressor_svr_saude_rbf.predict(x_plano_saude2), name = 'Regressão')
grafico.show()

# normalização dos dados
# calcula a média e o desvio padrão para deixar os dados na mesma escala

from sklearn.preprocessing import StandardScaler
scaler_x = StandardScaler()
x_plano_saude2_scaled = scaler_x.fit_transform(x_plano_saude2)

# igual processo para y
from sklearn.preprocessing import StandardScaler
scaler_y = StandardScaler()
y_plano_saude2_scaled = scaler_y.fit_transform(y_plano_saude2.reshape(-1,1))   #muda para matriz

# normalizado
x_plano_saude2_scaled

# normalizado

y_plano_saude2_scaled

# kernel rbf com atributos normalizados
# treinamento

regressor_svr_saude_rbf = SVR(kernel='rbf')
regressor_svr_saude_rbf.fit(x_plano_saude2_scaled, y_plano_saude2_scaled.ravel())   #muda para vetor

# repetindo o comando para o gráfico, com atributos normalizados

grafico = px.scatter(x = x_plano_saude2_scaled.ravel(), y= y_plano_saude2_scaled.ravel())
grafico.add_scatter(x = x_plano_saude2_scaled.ravel(), y= regressor_svr_saude_rbf.predict(x_plano_saude2_scaled), name = 'Regressão')
grafico.show()

"""**6.4 PREVISÃO**"""

# Quanto uma pessoa de 40 anos pagaria pelo plano de saúde?

novo = [[40]]  # foi treinado com valor real

novo = scaler_x.transform(novo)   # precisa escalonar
novo

# para o preço do plano de saúde

regressor_svr_saude_rbf.predict(novo)

#scaler_y.inverse_transform(regressor_svr_saude_rbf.predict(novo))